# Copyright (c) 2025 VortexBench Team
# SPDX-License-Identifier: Apache-2.0

# VortexBench Evaluation Prompts
# 5 core metrics: reasoning_process, reasoning_visual, reasoning_alignment, visual_consistency, image_quality

prompt_reasoning_process_temporal = """
You are a professional AI evaluation specialist with expertise in temporal reasoning assessment.

You will be given:
1. **Original Image**: the starting point
2. **Task Instruction**: the temporal reasoning task to perform  
3. **Dimension**: the knowledge domain (science/humanity/common_sense/logic)
4. **Keywords**: relevant domain concepts and principles for this task
5. **Target Description**: expected visual outcomes after temporal reasoning
6. **Think Output**: the reasoning text generated by the model

Your Objective:
Evaluate ONLY the **actual text content** provided in the "Think Output" section. You must analyze the reasoning quality based solely on what is written there. Do NOT generate or evaluate your own reasoning - only assess the provided text.

CRITICAL: If the Think Output is empty, contains only placeholder text, or says "No think output available", you MUST give a score of 1 and explain that no actual reasoning was provided. Do NOT create your own reasoning to evaluate.

Note: Keywords are domain-specific concepts that should be considered or applied in the reasoning. Target Description shows what the final visual outcome should look like, helping you assess if the reasoning process is heading in the right direction.

## Process Evaluation Criteria:
- **Logical Structure**: Is the reasoning well-organized and sequential?
- **Domain Knowledge**: Does the text show correct understanding of domain principles?
- **Temporal Logic**: Does the reasoning follow correct temporal causality?
- **Completeness**: Are all necessary reasoning steps included?

## Evaluation Steps:
1. **Parse Reasoning Steps**: Extract the main reasoning steps and conclusions from think output
2. **Domain Knowledge Check**: Verify keyword-related principles and target description are correctly applied in text
3. **Temporal Logic Validation**: Check temporal causality and progression logic in reasoning
4. **Completeness Assessment**: Ensure no critical reasoning steps are missing from the process

## Evaluation Scale (1 to 5):
- **5 Perfect Process Logic**: All reasoning steps are logically sound and domain-accurate
- **4 Minor Process Issues**: One small logical gap or minor domain knowledge error in text
- **3 Noticeable Process Problems**: Clear reasoning flaws in text but overall direction correct
- **2 Major Process Failures**: Multiple serious logical errors that undermine written reasoning
- **1 Process Logic Breakdown**: Written reasoning is fundamentally flawed or missing

### Example: Plant Growth
**Task**: "Show what this seedling will look like after 3 months"
**Think Output**: "I need to consider how plants grow over time. In 3 months, through photosynthesis, the leaves will expand to capture more sunlight, the stem will elongate to support the growing plant, and the root system will develop underground to absorb more nutrients."

**Evaluation**:
1. **Process Steps**: ✔ Identifies photosynthesis as growth mechanism, ✔ Considers multiple plant parts
2. **Domain Knowledge**: ✔ Correctly applies plant biology principles, ✔ 3-month timeframe appropriate
3. **Temporal Logic**: ✔ Sequential growth process described, ✔ Cause-effect relationships clear
4. **Completeness**: ✔ Major growth aspects covered, ✔ Underground and above-ground development

→ **reasoning_process_score**: 5 (Comprehensive and accurate reasoning process)

## Input
**Original Image**
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}
**Think Output**: {think_output}

## Output Format
{{
  "reasoning_process_score": X,
  "reasoning": "1. Process Steps 2. Domain Knowledge Check 3. Temporal Logic Validation 4. Completeness Assessment"
}}
"""

prompt_reasoning_visual_temporal = """
You are a professional AI evaluation specialist with expertise in temporal reasoning assessment.

You will be given:
1. **Original Image**: the starting point
2. **Generated Image**: the result after temporal reasoning
3. **Task Instruction**: the temporal reasoning task to perform  
4. **Dimension**: the knowledge domain (science/humanity/common_sense/logic)
5. **Keywords**: relevant domain concepts and principles for this task
6. **Target Description**: expected visual outcomes after temporal reasoning
7. **Target Image** (if available): reference image showing the expected result

Note: Keywords are domain-specific concepts that should be considered or applied in the reasoning. Target Description shows what the final visual outcome should look like, helping you assess if the visual result aligns with expectations. If a Target Image is provided, use it as the primary reference for evaluation; otherwise, rely on the Target Description.

Your Objective:
Evaluate whether the **generated image** matches the target description (and target image if available) and demonstrates correct temporal reasoning. Focus on comparing the visual result with the expected outcomes.

## Visual Temporal Logic Principles:
- **Sequential Progression**: Visual changes follow natural temporal order
- **Causality Over Time**: Each visual stage logically leads to the next  
- **Process Continuity**: No impossible visual jumps or missing critical stages
- **Time-Scale Consistency**: Visual changes match the specified time duration

## Domain-Specific Considerations:
- **Science**: Apply scientific principles and natural laws
- **Humanity**: Consider cultural, historical, and social contexts  
- **Common Sense**: Use everyday knowledge and practical understanding
- **Logic**: Follow formal reasoning and mathematical principles

## Evaluation Steps:
1. **Target Match**: Does the generated image match the target description (and target image if available)?
2. **Visual Changes Analysis**: What has visually changed from original to generated image?
3. **Domain Knowledge Check**: Do visual changes align with keyword-related principles?
4. **Temporal Logic Validation**: Is the visual progression temporally sound?

## Evaluation Scale (1 to 5):
- **5 Perfect Target Match**: Generated image **precisely matches** target description (and target image if available) with **flawless temporal logic**; all required temporal changes are present and accurate with **zero gaps or errors**
- **4 Minor Target Gaps**: The core temporal change is made, but **minor detail** is missing or slightly incorrect; strong overall match with minimal gaps
- **3 Partial Target Match**: The main temporal idea is present, but **one or more required aspects** are wrong or incomplete; notable gaps exist
- **2 Major Target Gaps**: **Most of the required temporal changes** are missing or poorly implemented; major gaps in target description fulfillment
- **1 Target Mismatch**: The temporal reasoning is **not followed at all** or is **completely misinterpreted**; fundamental logical errors

### Example: Plant Growth
**Task**: "Show what this seedling will look like after 3 months"
**Dimension**: "science"
**Keywords**: "plant development, photosynthesis, growth"
**Target Description**: "leaves expanded and more numerous; stem visibly longer; root system extended underground"

**Evaluation**:
1. **Visual Changes**: ✔ Leaves expanded, ✔ Stem elongated, ✘ Root system not visible
2. **Domain Knowledge**: ✔ Growth follows photosynthesis principles, ✔ 3-month timeframe appropriate
3. **Temporal Logic**: ✔ Sequential development stages shown, ✘ Missing intermediate growth phases
4. **Completeness**: ✔ Major growth visible, ✘ Underground development not represented

→ **reasoning_visual_score**: 4 (Strong visual progression but incomplete representation)

## Input
**Image 1: Original Image** (the starting point)
**Image 2: Generated Image** (the result after temporal reasoning)
**Image 3: Target Image** (if available, the reference showing expected result)
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}

## Output Format
{{
  "reasoning_visual_score": X,
  "reasoning": "1. Target Match 2. Visual Changes Analysis 3. Domain Knowledge Check 4. Temporal Logic Validation"
}}
"""

prompt_reasoning_process_spatial = """
You are a professional AI evaluation specialist with expertise in spatial reasoning assessment.

You will be given:
1. **Original Image**: the starting point  
2. **Task Instruction**: the spatial reasoning task to perform
3. **Dimension**: the knowledge domain (science/humanity/common_sense/logic)
4. **Keywords**: relevant domain concepts and principles for this task
5. **Target Description**: expected visual outcomes after spatial reasoning
6. **Think Output**: the reasoning text generated by the model

Your Objective:
Evaluate ONLY the **actual text content** provided in the "Think Output" section. You must analyze the reasoning quality based solely on what is written there. Do NOT generate or evaluate your own reasoning - only assess the provided text.

CRITICAL: If the Think Output is empty, contains only placeholder text, or says "No think output available", you MUST give a score of 1 and explain that no actual reasoning was provided. Do NOT create your own reasoning to evaluate.

Note: Keywords are domain-specific concepts that should be considered or applied in the reasoning. Target Description shows what the final visual outcome should look like, helping you assess if the reasoning process is heading in the right direction.

## Spatial Logic Principles:
- **Geometric Consistency**: Shapes, proportions, and relationships are maintained
- **Perspective Accuracy**: Viewpoint changes follow optical laws
- **Spatial Relationships**: Relative positions and orientations are logical
- **Transformation Validity**: Rotations, translations, scaling are geometrically sound

## Domain-Specific Considerations:
- **Science**: Apply scientific principles and natural laws
- **Humanity**: Consider cultural, historical, and social contexts  
- **Common Sense**: Use everyday knowledge and practical understanding
- **Logic**: Follow formal reasoning and mathematical principles

## Evaluation Steps:
1. **Identify Spatial Changes**: What spatial transformations occurred?
2. **Domain Knowledge Check**: Do changes follow keyword-related principles and target description?
3. **Geometric Validation**: Are transformations geometrically valid?
4. **Consistency Assessment**: Are spatial relationships maintained correctly?

## Evaluation Scale (1 to 5):
- **5 Perfect Spatial Logic**: All spatial transformations follow geometric and domain principles flawlessly
- **4 Minor Spatial Issues**: One small geometric inconsistency that doesn't break overall logic
- **3 Noticeable Spatial Problems**: Clear spatial logic flaws but general transformation correct
- **2 Major Spatial Failures**: Multiple serious geometric errors that undermine reasoning
- **1 Spatial Logic Breakdown**: Spatial transformation violates fundamental geometric principles

### Example: Architectural Rotation
**Task**: "Show this building from a 45-degree side view"
**Dimension**: "humanity"
**Keywords**: "architectural proportions, structural logic, perspective"
**Target Description**: "building viewed from 45-degree side angle with preserved proportions"

**Evaluation**:
1. **Spatial Changes**: ✔ Viewpoint rotated 45 degrees, ✔ Building perspective adjusted
2. **Domain Knowledge**: ✔ Architectural proportions preserved, ✔ Structural logic maintained
3. **Geometric Validation**: ✔ Perspective transformation accurate, ✘ Window spacing slightly distorted
4. **Consistency**: ✔ Overall spatial relationships correct, ✘ Minor depth inconsistencies

→ **reasoning_process_score**: 4 (Solid spatial reasoning with minor geometric imperfections)

## Input
**Original Image**
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}
**Think Output**: {think_output}

## Output Format
{{
  "reasoning_process_score": X,
  "reasoning": "1. Spatial Changes 2. Domain Knowledge Check 3. Geometric Validation 4. Consistency Assessment"
}}
"""

prompt_reasoning_visual_spatial = """
You are a professional AI evaluation specialist with expertise in spatial reasoning assessment.

You will be given:
1. **Original Image**: the starting point  
2. **Generated Image**: the result after spatial reasoning
3. **Task Instruction**: the spatial reasoning task to perform
4. **Dimension**: the knowledge domain (science/humanity/common_sense/logic)
5. **Keywords**: relevant domain concepts and principles for this task
6. **Target Description**: expected visual outcomes after spatial reasoning
7. **Target Image** (if available): reference image showing the expected result

Note: Keywords are domain-specific concepts that should be considered or applied in the reasoning. Target Description shows what the final visual outcome should look like, helping you assess if the visual result aligns with expectations. If a Target Image is provided, use it as the primary reference for evaluation; otherwise, rely on the Target Description.

Your Objective:
Evaluate whether the **generated image** matches the target description (and target image if available) and demonstrates correct spatial reasoning. Focus on comparing the visual result with the expected outcomes.

## Visual Spatial Logic Principles:
- **Geometric Consistency**: Visual shapes, proportions, and relationships are maintained
- **Perspective Accuracy**: Visual viewpoint changes follow optical laws
- **Spatial Relationships**: Visual relative positions and orientations are logical
- **Transformation Validity**: Visual rotations, translations, scaling are geometrically sound

## Domain-Specific Considerations:
- **Science**: Apply scientific principles and natural laws
- **Humanity**: Consider cultural, historical, and social contexts  
- **Common Sense**: Use everyday knowledge and practical understanding
- **Logic**: Follow formal reasoning and mathematical principles

## Evaluation Steps:
1. **Target Match**: Does the generated image match the target description (and target image if available)?
2. **Visual Changes Analysis**: What spatial transformations are visually apparent?
3. **Domain Knowledge Check**: Do visual changes align with keyword-related principles?
4. **Geometric Validation**: Are visual transformations geometrically valid?

## Evaluation Scale (1 to 5):
- **5 Perfect Target Match**: Generated image perfectly matches target description (and target image if available) with correct spatial logic
- **4 Minor Target Gaps**: Most target elements present and correct, with one minor missing or incorrect detail
- **3 Partial Target Match**: Some target elements present but notable gaps or inaccuracies in matching target description
- **2 Limited Target Achievement**: Few target elements correctly present, major gaps in target description fulfillment
- **1 Target Mismatch**: Generated image fails to match target description or shows fundamental logical errors

## Input
**Image 1: Original Image** (the starting point)
**Image 2: Generated Image** (the result after spatial reasoning)
**Image 3: Target Image** (if available, the reference showing expected result)
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}

## Output Format
{{
  "reasoning_visual_score": X,
  "reasoning": "1. Target Match 2. Visual Changes Analysis 3. Domain Knowledge Check 4. Geometric Validation"
}}
"""

prompt_reasoning_process_quantitative = """
You are a professional AI evaluation specialist with expertise in quantitative reasoning assessment.

You will be given:
1. **Original Image**: the starting point
2. **Task Instruction**: the quantitative reasoning task to perform
3. **Dimension**: the knowledge domain (science/humanity/common_sense/logic)
4. **Keywords**: relevant domain concepts and principles for this task
5. **Target Description**: expected visual outcomes after quantitative reasoning
6. **Think Output**: the reasoning text generated by the model

Your Objective:
Evaluate ONLY the **actual text content** provided in the "Think Output" section. You must analyze the reasoning quality based solely on what is written there. Do NOT generate or evaluate your own reasoning - only assess the provided text.

CRITICAL: If the Think Output is empty, contains only placeholder text, or says "No think output available", you MUST give a score of 1 and explain that no actual reasoning was provided. Do NOT create your own reasoning to evaluate.

Note: Keywords are domain-specific concepts that should be considered or applied in the reasoning. Target Description shows what the final visual outcome should look like, helping you assess if the reasoning process is heading in the right direction.

## Quantitative Logic Principles:
- **Mathematical Relationships**: Numbers, ratios, and proportions are correct
- **Scale Consistency**: Size relationships follow mathematical rules
- **Measurement Accuracy**: Quantities align with specified changes
- **Proportional Changes**: Increases/decreases maintain logical ratios

## Domain-Specific Considerations:
- **Science**: Apply scientific principles and natural laws
- **Humanity**: Consider cultural, historical, and social contexts  
- **Common Sense**: Use everyday knowledge and practical understanding
- **Logic**: Follow formal reasoning and mathematical principles

## Evaluation Steps:
1. **Identify Quantitative Changes**: What numerical/proportional changes occurred?
2. **Domain Knowledge Check**: Do quantities align with keyword-related principles and target description?
3. **Mathematical Validation**: Are calculations and proportions mathematically sound?
4. **Scale Assessment**: Are size/amount relationships logically consistent?

## Evaluation Scale (1 to 5):
- **5 Perfect Quantitative Logic**: All quantities and proportions follow mathematical and domain principles flawlessly
- **4 Minor Quantitative Issues**: One small numerical inconsistency that doesn't break overall logic
- **3 Noticeable Quantitative Problems**: Clear mathematical flaws but general direction correct
- **2 Major Quantitative Failures**: Multiple serious numerical errors that undermine reasoning
- **1 Quantitative Logic Breakdown**: Mathematical relationships violate fundamental principles

### Example: Fruit Quantity Change
**Task**: "Change the number of apples in this basket to exactly 10"
**Dimension**: "common_sense"
**Keywords**: "counting, object identification, numerical accuracy"
**Target Description**: "exactly 10 clearly countable apples in the basket"

**Evaluation**:
1. **Quantitative Changes**: ✔ Apple count changed from 6 to 10, ✔ New apples added appropriately
2. **Domain Knowledge**: ✔ Apples are visually distinct and countable, ✔ Basket size accommodates 10 apples
3. **Mathematical Validation**: ✔ Exact count of 10 achieved, ✘ One apple partially obscured by another
4. **Scale Assessment**: ✔ Apple sizes consistent, ✔ Spatial arrangement logical

→ **reasoning_process_score**: 4 (Accurate quantitative reasoning with minor visibility issue)

## Input
**Original Image**
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}
**Think Output**: {think_output}

## Output Format
{{
  "reasoning_process_score": X,
  "reasoning": "1. Quantitative Changes 2. Domain Knowledge Check 3. Mathematical Validation 4. Scale Assessment"
}}
"""

prompt_reasoning_visual_quantitative = """
You are a professional AI evaluation specialist with expertise in quantitative reasoning assessment.

You will be given:
1. **Original Image**: the starting point
2. **Generated Image**: the result after quantitative reasoning  
3. **Task Instruction**: the quantitative reasoning task to perform
4. **Dimension**: the knowledge domain (science/humanity/common_sense/logic)
5. **Keywords**: relevant domain concepts and principles for this task
6. **Target Description**: expected visual outcomes after quantitative reasoning
7. **Target Image** (if available): reference image showing the expected result

Note: Keywords are domain-specific concepts that should be considered or applied in the reasoning. Target Description shows what the final visual outcome should look like, helping you assess if the visual result aligns with expectations. If a Target Image is provided, use it as the primary reference for evaluation; otherwise, rely on the Target Description.

Your Objective:
Evaluate whether the **generated image** matches the target description (and target image if available) and demonstrates correct quantitative reasoning. Focus on comparing the visual result with the expected outcomes.

## Visual Quantitative Logic Principles:
- **Mathematical Relationships**: Visual numbers, ratios, and proportions are correct
- **Scale Consistency**: Visual size relationships follow mathematical rules
- **Measurement Accuracy**: Visual quantities align with specified changes
- **Proportional Changes**: Visual increases/decreases maintain logical ratios

## Domain-Specific Considerations:
- **Science**: Apply scientific principles and natural laws
- **Humanity**: Consider cultural, historical, and social contexts  
- **Common Sense**: Use everyday knowledge and practical understanding
- **Logic**: Follow formal reasoning and mathematical principles

## Evaluation Steps:
1. **Target Match**: Does the generated image match the target description (and target image if available)?
2. **Visual Changes Analysis**: What numerical/proportional changes are visually apparent?
3. **Domain Knowledge Check**: Do visual changes align with keyword-related principles?
4. **Mathematical Validation**: Are visual calculations and proportions mathematically sound?

## Evaluation Scale (1 to 5):
- **5 Perfect Target Match**: Generated image perfectly matches target description (and target image if available) with correct quantitative logic
- **4 Minor Target Gaps**: Most target elements present and correct, with one minor missing or incorrect detail
- **3 Partial Target Match**: Some target elements present but notable gaps or inaccuracies in matching target description
- **2 Limited Target Achievement**: Few target elements correctly present, major gaps in target description fulfillment
- **1 Target Mismatch**: Generated image fails to match target description or shows fundamental logical errors

## Input
**Image 1: Original Image** (the starting point)
**Image 2: Generated Image** (the result after quantitative reasoning)
**Image 3: Target Image** (if available, the reference showing expected result)
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}

## Output Format
{{
  "reasoning_visual_score": X,
  "reasoning": "1. Target Match 2. Visual Changes Analysis 3. Domain Knowledge Check 4. Mathematical Validation"
}}
"""

prompt_reasoning_process_causal = """
You are a professional AI evaluation specialist with expertise in causal reasoning assessment.

You will be given:
1. **Original Image**: the starting point
2. **Task Instruction**: the causal reasoning task to perform
3. **Dimension**: the knowledge domain (science/humanity/common_sense/logic)
4. **Keywords**: relevant domain concepts and principles for this task
5. **Target Description**: expected visual outcomes after causal reasoning
6. **Think Output**: the reasoning text generated by the model

Your Objective:
Evaluate ONLY the **actual text content** provided in the "Think Output" section. You must analyze the reasoning quality based solely on what is written there. Do NOT generate or evaluate your own reasoning - only assess the provided text.

CRITICAL: If the Think Output is empty, contains only placeholder text, or says "No think output available", you MUST give a score of 1 and explain that no actual reasoning was provided. Do NOT create your own reasoning to evaluate.

Note: Keywords are domain-specific concepts that should be considered or applied in the reasoning. Target Description shows what the final visual outcome should look like, helping you assess if the reasoning process is heading in the right direction.

## Causal Logic Principles:
- **Cause-Effect Relationships**: Clear connection between cause and observed effect
- **Mechanism Consistency**: Intermediate steps follow logical causal chains
- **Intervention Logic**: Applied changes produce expected outcomes
- **Causal Completeness**: All necessary causal factors are represented

## Domain-Specific Considerations:
- **Science**: Apply scientific principles and natural laws
- **Humanity**: Consider cultural, historical, and social contexts  
- **Common Sense**: Use everyday knowledge and practical understanding
- **Logic**: Follow formal reasoning and mathematical principles

## Evaluation Steps:
1. **Identify Causal Chain**: What cause-effect sequence is demonstrated?
2. **Domain Knowledge Check**: Does causation follow keyword-related principles and target description?
3. **Mechanism Validation**: Are causal steps logically connected and complete?
4. **Effect Assessment**: Do observed effects match expected causal outcomes?

## Evaluation Scale (1 to 5):
- **5 Perfect Causal Logic**: All cause-effect relationships follow domain principles flawlessly
- **4 Minor Causal Issues**: One small causal inconsistency that doesn't break overall logic
- **3 Noticeable Causal Problems**: Clear causal logic flaws but general direction correct
- **2 Major Causal Failures**: Multiple serious causal errors that undermine reasoning
- **1 Causal Logic Breakdown**: Cause-effect relationships violate fundamental principles

### Example: Potato Oxidation Prevention
**Task**: "Apply lemon juice to prevent these cut potatoes from browning"
**Dimension**: "science"
**Keywords**: "citric acid, enzymatic browning, oxidation prevention"
**Target Description**: "cut potatoes remain white/pale after lemon juice application"

**Evaluation**:
1. **Causal Chain**: ✔ Lemon juice applied to potato surfaces, ✔ Potatoes remain white/pale
2. **Domain Knowledge**: ✔ Citric acid prevents browning, ✔ Application method appropriate
3. **Mechanism Validation**: ✔ Chemical prevention process shown, ✘ Some areas missed during application
4. **Effect Assessment**: ✔ Most potato pieces remain unbrowned, ✘ One piece shows slight browning

→ **reasoning_process_score**: 4 (Sound causal reasoning with minor application gaps)

## Input
**Original Image**
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}
**Think Output**: {think_output}

## Output Format
{{
  "reasoning_process_score": X,
  "reasoning": "1. Causal Chain 2. Domain Knowledge Check 3. Mechanism Validation 4. Effect Assessment"
}}
"""

prompt_reasoning_visual_causal = """
You are a professional AI evaluation specialist with expertise in causal reasoning assessment.

You will be given:
1. **Original Image**: the starting point
2. **Generated Image**: the result after causal reasoning
3. **Task Instruction**: the causal reasoning task to perform
4. **Dimension**: the knowledge domain (science/humanity/common_sense/logic)
5. **Keywords**: relevant domain concepts and principles for this task
6. **Target Description**: expected visual outcomes after causal reasoning
7. **Target Image** (if available): reference image showing the expected result

Note: Keywords are domain-specific concepts that should be considered or applied in the reasoning. Target Description shows what the final visual outcome should look like, helping you assess if the visual result aligns with expectations. If a Target Image is provided, use it as the primary reference for evaluation; otherwise, rely on the Target Description.

Your Objective:
Evaluate whether the **visual changes** in the generated image correctly demonstrate causal reasoning following domain principles. Focus on comparing the visual result with the expected outcomes.

## Visual Causal Logic Principles:
- **Cause-Effect Relationships**: Visual changes show clear cause-effect connections
- **Mechanism Consistency**: Visual intermediate steps follow logical causal chains
- **Intervention Logic**: Visual applied changes produce expected outcomes
- **Causal Completeness**: Visual representation includes necessary causal factors

## Domain-Specific Considerations:
- **Science**: Apply scientific principles and natural laws
- **Humanity**: Consider cultural, historical, and social contexts  
- **Common Sense**: Use everyday knowledge and practical understanding
- **Logic**: Follow formal reasoning and mathematical principles

## Evaluation Steps:
1. **Target Match**: Does the generated image match the target description (and target image if available)?
2. **Visual Changes Analysis**: What causal effects are visually apparent?
3. **Domain Knowledge Check**: Do visual changes align with keyword-related principles?
4. **Mechanism Validation**: Are visual causal steps logically connected and complete?

## Evaluation Scale (1 to 5):
- **5 Perfect Target Match**: Generated image perfectly matches target description (and target image if available) with correct causal logic
- **4 Minor Target Gaps**: Most target elements present and correct, with one minor missing or incorrect detail
- **3 Partial Target Match**: Some target elements present but notable gaps or inaccuracies in matching target description
- **2 Limited Target Achievement**: Few target elements correctly present, major gaps in target description fulfillment
- **1 Target Mismatch**: Generated image fails to match target description or shows fundamental logical errors

## Input
**Image 1: Original Image** (the starting point)
**Image 2: Generated Image** (the result after causal reasoning)
**Image 3: Target Image** (if available, the reference showing expected result)
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}

## Output Format
{{
  "reasoning_visual_score": X,
  "reasoning": "1. Target Match 2. Visual Changes Analysis 3. Domain Knowledge Check 4. Mechanism Validation"
}}
"""

prompt_reasoning_visual_synthetic = """
You are a professional AI evaluation specialist with expertise in synthetic reasoning assessment.

You will be given:
1. **Original Image**: the starting point
2. **Generated Image**: the result after synthetic reasoning
3. **Task Instruction**: the synthetic reasoning task to perform
4. **Dimension**: the knowledge domain (science/humanity/common_sense/logic)
5. **Keywords**: relevant domain concepts and principles for this task
6. **Target Description**: expected visual outcomes after synthetic reasoning
7. **Target Image** (if available): reference image showing the expected result

Note: Keywords are domain-specific concepts that should be considered or applied in the reasoning. Target Description shows what the final visual outcome should look like, helping you assess if the visual result aligns with expectations. If a Target Image is provided, use it as the primary reference for evaluation; otherwise, rely on the Target Description.

Your Objective:
Evaluate whether the **visual changes** in the generated image correctly demonstrate synthetic reasoning following domain principles. Focus on comparing the visual result with the expected outcomes.

## Visual Synthetic Logic Principles:
- **Creative Plausibility**: Visual new/modified objects are realistic and believable
- **Coherent Integration**: Visual added elements blend naturally with existing scene
- **Attribute Consistency**: Visual object transformations maintain logical properties
- **Style Harmonization**: Visual synthetic elements match overall visual style

## Domain-Specific Considerations:
- **Science**: Apply scientific principles and natural laws
- **Humanity**: Consider cultural, historical, and social contexts  
- **Common Sense**: Use everyday knowledge and practical understanding
- **Logic**: Follow formal reasoning and mathematical principles

## Evaluation Steps:
1. **Target Match**: Does the generated image match the target description (and target image if available)?
2. **Visual Changes Analysis**: What synthetic transformations are visually apparent?
3. **Domain Knowledge Check**: Do visual changes align with keyword-related principles?
4. **Plausibility Validation**: Are visual new/modified objects realistic and logically sound?

## Evaluation Scale (1 to 5):
- **5 Perfect Target Match**: Generated image perfectly matches target description (and target image if available) with correct synthetic logic
- **4 Minor Target Gaps**: Most target elements present and correct, with one minor missing or incorrect detail
- **3 Partial Target Match**: Some target elements present but notable gaps or inaccuracies in matching target description
- **2 Limited Target Achievement**: Few target elements correctly present, major gaps in target description fulfillment
- **1 Target Mismatch**: Generated image fails to match target description or shows fundamental logical errors

## Input
**Image 1: Original Image** (the starting point)
**Image 2: Generated Image** (the result after synthetic reasoning)
**Image 3: Target Image** (if available, the reference showing expected result)
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}

## Output Format
{{
  "reasoning_visual_score": X,
  "reasoning": "1. Target Match 2. Visual Changes Analysis 3. Domain Knowledge Check 4. Plausibility Validation"
}}
"""

prompt_reasoning_process_synthetic = """
You are a professional AI evaluation specialist with expertise in synthetic reasoning assessment.

You will be given:
1. **Original Image**: the starting point
2. **Task Instruction**: the synthetic reasoning task to perform
3. **Dimension**: the knowledge domain (science/humanity/common_sense/logic)
4. **Keywords**: relevant domain concepts and principles for this task
5. **Target Description**: expected visual outcomes after synthetic reasoning
6. **Think Output**: the reasoning text generated by the model

Your Objective:
Evaluate ONLY the **actual text content** provided in the "Think Output" section. You must analyze the reasoning quality based solely on what is written there. Do NOT generate or evaluate your own reasoning - only assess the provided text.

CRITICAL: If the Think Output is empty, contains only placeholder text, or says "No think output available", you MUST give a score of 1 and explain that no actual reasoning was provided. Do NOT create your own reasoning to evaluate.

Note: Keywords are domain-specific concepts that should be considered or applied in the reasoning. Target Description shows what the final visual outcome should look like, helping you assess if the reasoning process is heading in the right direction.

## Synthetic Logic Principles:
- **Creative Plausibility**: New/modified objects are realistic and believable
- **Coherent Integration**: Added elements blend naturally with existing scene
- **Attribute Consistency**: Object transformations maintain logical properties
- **Style Harmonization**: Synthetic elements match overall visual style

## Domain-Specific Considerations:
- **Science**: Apply scientific principles and natural laws
- **Humanity**: Consider cultural, historical, and social contexts  
- **Common Sense**: Use everyday knowledge and practical understanding
- **Logic**: Follow formal reasoning and mathematical principles

## Evaluation Steps:
1. **Identify Synthetic Changes**: What objects were added, modified, or transformed?
2. **Domain Knowledge Check**: Do synthetic elements follow keyword-related principles and target description?
3. **Plausibility Validation**: Are new/modified objects realistic and logically sound?
4. **Integration Assessment**: Do synthetic elements harmonize with the original scene?

## Evaluation Scale (1 to 5):
- **5 Perfect Synthetic Logic**: All synthetic elements are plausible, well-integrated, and domain-appropriate
- **4 Minor Synthetic Issues**: One small implausibility that doesn't break overall coherence
- **3 Noticeable Synthetic Problems**: Clear logic flaws but general synthesis direction correct
- **2 Major Synthetic Failures**: Multiple serious errors that undermine creative reasoning
- **1 Synthetic Logic Breakdown**: Synthetic elements violate fundamental plausibility principles

### Example: Fruit Platter Creation
**Task**: "Arrange these various fruits into an attractive fruit platter"
**Dimension**: "common_sense"
**Keywords**: "visual appeal, color balance, size hierarchy, accessibility"
**Target Description**: "fruits arranged in an attractive platter with good color distribution and accessibility"

**Evaluation**:
1. **Synthetic Changes**: ✔ Fruits arranged on platter, ✔ Different varieties distributed evenly
2. **Domain Knowledge**: ✔ Color balance achieved, ✔ Size hierarchy logical (large to small)
3. **Plausibility Validation**: ✔ Arrangement practically achievable, ✘ Some fruits may roll off edges
4. **Integration Assessment**: ✔ Visual harmony maintained, ✔ All fruits remain recognizable

→ **reasoning_process_score**: 4 (Practical synthesis with minor stability concerns)

## Input
**Original Image**
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}
**Think Output**: {think_output}

## Output Format
{{
  "reasoning_process_score": X,
  "reasoning": "1. Synthetic Changes 2. Domain Knowledge Check 3. Plausibility Validation 4. Integration Assessment"
}}
"""

prompt_reasoning_alignment = """
You are a professional AI evaluation specialist focusing on process-visual reasoning alignment assessment.

You will be given:
1. **Original Image**: the starting point
2. **Generated Image**: the reasoning result
3. **Task Instruction**: what reasoning should be performed
4. **Think Output**: the reasoning process text generated by the model

Your Objective:
Evaluate whether the **reasoning process text** and the **visual reasoning result** are aligned and consistent with each other. Focus on whether what the model thought and what the model visually produced match.

## Alignment Evaluation Criteria:
- **Process-Visual Consistency**: Do the written reasoning steps match the visual changes?
- **Conclusion Coherence**: Do text conclusions align with visual outcomes?
- **Step-by-Step Alignment**: Does each reasoning step in text correspond to visual evidence?
- **Logical Consistency**: Are there contradictions between thought process and visual result?

## Key Questions:
1. **Does the visual result reflect the written reasoning?** Are the visual changes consistent with what was described in the think output?
2. **Are the conclusions aligned?** Do both process and visual reasoning reach the same conclusions?
3. **Is the reasoning coherent?** Are there contradictions between what was thought and what was visually produced?

## Evaluation Scale (1 to 5):
- **5 Perfect Alignment**: Process text and visual result are **completely consistent** and mutually supporting with **zero contradictions**; all process claims match visual evidence exactly
- **4 Minor Misalignment**: Strong overall alignment with **minimal inconsistencies** that don't affect core reasoning; only very minor discrepancies
- **3 Partial Alignment**: Some alignment present but **clear discrepancies** between process and visual reasoning; notable inconsistencies exist
- **2 Poor Alignment**: **Minimal alignment** with major contradictions between written process and visual result; significant mismatches
- **1 No Alignment**: Process text and visual result are **contradictory or completely unrelated**; no meaningful alignment

## Reasoning Steps:
1. **Extract Process Claims**: What does the think output claim will happen or should be done?
2. **Identify Visual Evidence**: What changes are actually visible in the generated image?
3. **Compare Alignment**: Do the process claims match the visual evidence?
4. **Assess Consistency**: Are there any contradictions between thought and visual result?

## Input
**Image 1: Original Image** (the starting point)
**Image 2: Generated Image** (the reasoning result)
**Task Instruction**: {prompt}
**Think Output**: {think_output}

## Output Format
{{
  "reasoning_alignment_score": X,
  "reasoning": "1. Process Claims 2. Visual Evidence 3. Alignment Comparison 4. Consistency Assessment"
}}
"""

prompt_visual_consistency = """
You are a professional visual evaluation specialist focusing on image consistency assessment.

You will be given:
1. **Original Image**: the starting point
2. **Generated Image**: the result after reasoning/editing
3. **Task Instruction**: the reasoning or editing task performed

Your Objective:
Evaluate whether **non-target elements** in the generated image remain **visually consistent** with the original image. Focus exclusively on elements that should NOT have changed according to the task instruction.

## Consistency Evaluation Guidelines:

### Elements to Preserve:
- **Background Elements**: Scenery, environment, setting details not mentioned in task
- **Unrelated Objects**: Items not involved in the reasoning/editing process  
- **Structural Elements**: Basic composition, layout, perspective (unless task requires change)
- **Identity Preservation**: People, animals, or objects should maintain their core identity
- **Style Consistency**: Overall visual style, lighting conditions, color palette

### Elements That May Change (Task-Dependent):
- **Target Objects**: Items explicitly mentioned in the task instruction
- **Direct Consequences**: Changes that logically result from the intended transformation
- **Process Effects**: Visual effects directly caused by the reasoning process

## Evaluation Scale (1 to 5):
- **5 Perfect Consistency**: All non-target elements remain **visually identical** to original with **zero unintended changes**; perfect preservation of all non-instructed elements
- **4 Minor Inconsistency**: **Minimal unintended changes** that are barely noticeable and don't affect coherence; only very small discrepancies
- **3 Noticeable Inconsistency**: **Clear unintended changes** in background or unrelated elements that affect coherence; notable inconsistencies exist
- **2 Significant Inconsistency**: **Multiple unintended changes** that significantly compromise visual coherence; major inconsistencies
- **1 Severe Inconsistency**: **Major unintended alterations** that make image appear largely different; fundamental consistency breakdown

## Reasoning Steps:
1. **Identify Target Elements**: What elements should change according to the task?
2. **Isolate Preserve Elements**: What elements should remain unchanged?
3. **Compare Preservation**: Are the preserve elements visually consistent with original?
4. **Assess Impact**: How do any inconsistencies affect overall visual coherence?

## Input
**Image 1: Original Image** (the starting point)
**Image 2: Generated Image** (the result after reasoning/editing)
**Task Instruction**: {prompt}

## Output Format
{{
  "visual_consistency_score": X,
  "reasoning": "1. Target Elements 2. Preserve Elements 3. Preservation Comparison 4. Impact Assessment"
}}
"""

prompt_image_quality = """
You are a professional image quality assessor specializing in AI-generated content evaluation.

You will be given:
1. **Generated Image**: an AI-generated image to evaluate

Your Objective:
Evaluate the **perceptual quality** of the AI-generated image, focusing on technical excellence, visual coherence, and absence of generation artifacts.

## Quality Assessment Dimensions:

### Structural Coherence
- **Anatomy/Geometry**: Correct proportions, realistic structures, proper object shapes
- **Spatial Relationships**: Logical positioning, appropriate scale relationships
- **Compositional Logic**: Coherent scene layout, proper perspective

### Visual Fidelity  
- **Texture Quality**: Realistic surface textures, appropriate material appearance
- **Detail Clarity**: Sharp important details, appropriate level of detail throughout
- **Color Accuracy**: Natural color distribution, proper lighting/shadow

### Generation Artifacts
- **Duplication Issues**: Repeated elements, phantom objects, merged features
- **Blending Problems**: Unnatural transitions, ghosting effects, edge artifacts
- **Distortion Errors**: Warped features, impossible geometries, scale inconsistencies

### Overall Naturalness
- **Photorealism**: Does the image look natural and believable?
- **Coherent Style**: Consistent visual style throughout the image
- **Professional Quality**: Would this pass as high-quality content?

## Evaluation Scale (1 to 5):
- **5 Excellent Quality**: **Professional-grade image** with **no noticeable artifacts or flaws**; perfect technical excellence and photorealistic quality
- **4 Good Quality**: **High-quality image** with **one minor flaw** that doesn't affect overall impression; minimal quality issues
- **3 Acceptable Quality**: **Decent image** with **some noticeable flaws** but overall usable; clear quality problems exist
- **2 Poor Quality**: **Multiple significant flaws** that detract from image usability; major quality problems
- **1 Very Poor Quality**: **Major structural problems**, severe artifacts, unusable quality; fundamental quality breakdown

## Quality Checklist:
For each dimension, mark ✓ (satisfactory) or ✗ (problematic):
- Structural coherence: ✓/✗
- Visual fidelity: ✓/✗  
- Artifact-free: ✓/✗
- Overall naturalness: ✓/✗

## Reasoning Steps:
1. **Structural Analysis**: Assess geometric and anatomical correctness
2. **Fidelity Evaluation**: Check texture, detail, and color quality
3. **Artifact Detection**: Identify any generation artifacts or distortions
4. **Naturalness Assessment**: Evaluate overall believability and professional quality

## Input
**Generated Image**

## Output Format
{{
  "image_quality_score": X,
  "reasoning": "1. Structural Analysis 2. Fidelity Evaluation 3. Artifact Detection 4. Naturalness Assessment"
}}
"""

# Logical Reasoning Prompts
prompt_reasoning_process_logical = """
You are an expert evaluator for logical reasoning tasks in visual AI systems. Your task is to assess the quality of written reasoning steps for logical, mathematical, and abstract reasoning tasks including games, puzzles, geometry, and pattern recognition.

## Task Context
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}

## Evaluation Criteria
Rate the reasoning process quality (1-5) based on four criteria. **Weight each criterion according to the task type:**

### 1. Game Strategy & Logic (Weight: High for games, Medium for others)
- Correct understanding of game rules and mechanics
- Strategic thinking and optimal move selection
- Pattern recognition in game states
- Logical deduction for winning/blocking moves

### 2. Mathematical & Geometric Reasoning (Weight: High for math/geometry, Medium for others)
- Accurate mathematical calculations and formulas
- Proper geometric principles and spatial relationships
- Correct handling of measurements and proportions
- Precise mathematical problem-solving steps

### 3. Abstract Pattern Recognition (Weight: High for patterns/RPM, Medium for others)
- Ability to identify visual patterns and sequences
- Logical abstraction from concrete examples
- Pattern completion and matrix reasoning
- Conceptual understanding of abstract relationships

### 4. Problem-Solving Methodology (Weight: Medium for all tasks)
- Systematic approach to complex problems
- Clear step-by-step reasoning progression
- Appropriate strategy selection for task type
- Effective decomposition of multi-step problems

**Scoring Guidelines:**
- **Games (tic-tac-toe, Connect Four, etc.)**: Weight Game Strategy heavily (40%), others equally (20% each)
- **Math/Geometry**: Weight Mathematical Reasoning heavily (40%), others equally (20% each)  
- **Patterns/RPM**: Weight Pattern Recognition heavily (40%), others equally (20% each)
- **Puzzles (tangram, maze)**: Weight Problem-Solving heavily (40%), others equally (20% each)

## Evaluation Scale (1 to 5):
- **5 Perfect Logical Process**: All reasoning steps are logically sound and domain-accurate with **flawless strategic thinking**; comprehensive understanding of task requirements
- **4 Minor Logical Issues**: One small logical gap or minor domain knowledge error in reasoning; strong overall logic with minimal gaps
- **3 Noticeable Logical Problems**: Clear reasoning flaws but general direction correct; notable gaps in logical progression
- **2 Major Logical Failures**: Multiple serious logical errors that undermine reasoning; major gaps in strategic thinking
- **1 Logical Breakdown**: Reasoning is fundamentally flawed or missing; no meaningful logical progression

## Quality Checklist:
For each criterion, mark ✓ (satisfactory) or ✗ (problematic):
- Game strategy & logic: ✓/✗
- Mathematical & geometric reasoning: ✓/✗
- Abstract pattern recognition: ✓/✗
- Problem-solving methodology: ✓/✗

## Reasoning Steps:
1. **Game Logic Analysis**: Evaluate strategic thinking and rule understanding
2. **Mathematical Review**: Check calculations and geometric reasoning
3. **Pattern Assessment**: Assess pattern recognition and abstract thinking
4. **Methodology Evaluation**: Review problem-solving approach and clarity

## Input
**Task Instruction**: {prompt}
**Think Output**: {think_output}

## Output Format
{{
  "reasoning_process_score": X,
  "reasoning": "1. Game Logic Analysis 2. Mathematical Review 3. Pattern Assessment 4. Methodology Evaluation"
}}
"""

prompt_reasoning_visual_logical = """
You are an expert evaluator for logical reasoning tasks in visual AI systems. Your task is to assess whether the generated visual result correctly implements the logical, mathematical, or abstract reasoning described in the task, including games, puzzles, geometry, and pattern recognition.

## Task Context
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}

## Evaluation Criteria
Rate the visual reasoning quality (1-5) based on four criteria. **Weight each criterion according to the task type:**

### 1. Game Logic Implementation (Weight: High for games, Medium for others)
- Correct game move execution (tic-tac-toe, Connect Four, etc.)
- Proper game state representation and board updates
- Accurate piece placement and movement rules
- Valid strategic positioning and winning conditions

### 2. Mathematical & Geometric Accuracy (Weight: High for math/geometry, Medium for others)
- Correct geometric calculations and measurements
- Accurate 3D spatial transformations and projections
- Proper mathematical annotations and formulas
- Precise geometric shape construction and manipulation

### 3. Pattern Recognition & Completion (Weight: High for patterns/RPM, Medium for others)
- Correct pattern identification and continuation
- Accurate matrix completion and sequence generation
- Proper visual pattern matching and abstraction
- Valid puzzle solution implementation (tangram, maze, etc.)

### 4. Target Alignment & Completeness (Weight: Medium for all tasks)
- Match with target description requirements
- Correct implementation of specified operations
- Appropriate handling of task constraints
- Successful achievement of reasoning goals

**Scoring Guidelines:**
- **Games (tic-tac-toe, Connect Four, etc.)**: Weight Game Logic heavily (40%), others equally (20% each)
- **Math/Geometry**: Weight Mathematical Accuracy heavily (40%), others equally (20% each)  
- **Patterns/RPM**: Weight Pattern Recognition heavily (40%), others equally (20% each)
- **Puzzles (tangram, maze)**: Weight Target Alignment heavily (40%), others equally (20% each)

## Evaluation Scale (1 to 5):
- **5 Perfect Target Match**: Generated image **precisely matches** target description (and target image if available) with **flawless logical implementation**; all required logical operations are present and accurate with **zero gaps or errors**
- **4 Minor Target Gaps**: The core logical operation is made, but **minor detail** is missing or slightly incorrect; strong overall match with minimal gaps
- **3 Partial Target Match**: The main logical idea is present, but **one or more required aspects** are wrong or incomplete; notable gaps exist
- **2 Major Target Gaps**: **Most of the required logical operations** are missing or poorly implemented; major gaps in target description fulfillment
- **1 Target Mismatch**: The logical reasoning is **not followed at all** or is **completely misinterpreted**; fundamental logical errors

## Quality Checklist:
For each criterion, mark ✓ (satisfactory) or ✗ (problematic):
- Game logic implementation: ✓/✗
- Mathematical & geometric accuracy: ✓/✗
- Pattern recognition & completion: ✓/✗
- Target alignment & completeness: ✓/✗

## Reasoning Steps:
1. **Game Logic Review**: Evaluate game move correctness and rule adherence
2. **Mathematical Verification**: Check geometric accuracy and calculations
3. **Pattern Analysis**: Assess pattern recognition and completion quality
4. **Target Comparison**: Verify alignment with expected results

## Input
**Image 1: Original Image** (the starting point)
**Image 2: Generated Image** (the result after logical reasoning)
**Image 3: Target Image** (if available, the reference showing expected result)
**Task Instruction**: {prompt}
**Dimension**: {dimension}
**Keywords**: {keywords}
**Target Description**: {target_description}

## Output Format
{{
  "reasoning_visual_score": X,
  "reasoning": "1. Game Logic Review 2. Mathematical Verification 3. Pattern Analysis 4. Target Comparison"
}}
"""
